---
date:
    created: 2024-11-29
draft: True
categories:
    - ML
tags:
    - Algorithm

---
# 逻辑回归

逻辑回归是用来解决二分类问题

<!-- more-->

## 概述

逻辑回归（Logistic Regression， LR）是一种用于分类任务的统计模型，其核心思想是利用线性回归模型的输出通过 **逻辑函数（sigmoid函数）** 进行映射，将预测值限制在 [0, 1] 区间，以便可以解释为概率。根据输出概率，逻辑回归可用于二分类、多分类任务。

逻辑回归是线性回归的一种扩展，用来处理分类问题。

先讲解线性回归与分类

**分类问题和回归问题有一定的相似性，都是通过对数据集的学习来对未知结果进行预测，区别在于输出值不同**。

- 分类问题的输出值是离散值（如垃圾邮件和正常邮件）。
- 回归问题的输出值是连续值（例如房子的价格）。

**既然分类问题和回归问题有一定的相似性，那么我们能不能在回归的基础上进行分类呢**？

可以想到的一种尝试思路是，先用线性拟合，然后对线性拟合的预测结果值进行量化，即将连续值量化为离散值——即 **使用『线性回归+阈值』解决分类问题** 。

## 核心思想

因为「线性回归+阈值」的方式很难得到鲁棒性好的分类器，我们对其进行拓展得到鲁棒性更好的逻辑回归（ Logistic Regression，也叫「对数几率回归」）。逻辑回归将数据拟合到一个logit函数中，从而完成对事件发生概率的预测。

如果线性回归的结果输出是一个 **连续值** ，而值的范围是无法限定的，这种情况下我们无法得到稳定的判定阈值。那是否可以把这个结果映射到一个固定大小的区间内（比如  [0, 1]之间）。

当然可以，这就是逻辑回归做的事情，而其中用于对连续值压缩变换的函数叫做 **Sigmoid 函数**（也称 Logistic 函数，S函数）。

**Sigmoid 函数** 是一个常见的S型数学函数，在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的阈值函数，将变量映射到0,1之间。在逻辑回归、人工神经网络中有着广泛的应用。Sigmoidi函数的数学形式是：

$$
f(z) = \frac{1}{1+e^{-z}}
$$

$$
z = W^TX + b \qquad (其中W为权重,b为偏移量)
$$

对x求导可以推出如下结论：
$$
f'(z) = \frac{e^{-z}}{(1+e^{-z})^2} = f(z)(1-f(z))
$$


![](../../../PageImage/Pasted%20image%2020241127220332.png)


因此，为了实现 Logistic 回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把所有结果值相加，将这个总和代入 Sigmoid 函数中，进而得到一个范围在 0~1 之间的数值。

Sigmoid 函数的输入记为 z ，则其为：

$$
z = w_0x_0 + w_1x_1 +\dots + w_nx_n
$$

如果采用向量的写法，那么公式可以写成向量形式，其为：$z = W^Tx$。其中向量 $x$ 是分类器的输入数据，向量 $w$ 也是我们需要找到的最佳参数。
